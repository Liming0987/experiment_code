{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "TRAIN_SUFFIX = '.train.csv'\n",
    "VALIDATION_SUFFIX = '.validation.csv'\n",
    "TEST_SUFFIX = '.test.csv'  # 测试集文件后缀\n",
    "\n",
    "INFO_SUFFIX = '.info.json'  # 数据集统计信息文件后缀\n",
    "USER_SUFFIX = '.user.csv'  # 数据集用户特征文件后缀\n",
    "ITEM_SUFFIX = '.item.csv'  # 数据集物品特征文件后缀\n",
    "\n",
    "TRAIN_POS_SUFFIX = '.train_pos.csv'  # 训练集用户正向交互按uid合并之后的文件后缀\n",
    "VALIDATION_POS_SUFFIX = '.validation_pos.csv'  # 验证集用户正向交互按uid合并之后的文件后缀\n",
    "TEST_POS_SUFFIX = '.test_pos.csv'  # 测试集用户正向交互按uid合并之后的文件后缀\n",
    "\n",
    "TRAIN_NEG_SUFFIX = '.train_neg.csv'  # 训练集用户负向交互按uid合并之后的文件后缀\n",
    "VALIDATION_NEG_SUFFIX = '.validation_neg.csv'  # 验证集用户负向交互按uid合并之后的文件后缀\n",
    "TEST_NEG_SUFFIX = '.test_neg.csv'  # 测试集用户负向交互按uid合并之后的文件后缀\n",
    "\n",
    "\n",
    "class DataLoader(object):\n",
    "\n",
    "    def __init__(self, path, dataset, label, sep='\\t'):\n",
    "        self.dataset = dataset\n",
    "        self.path = os.path.join(path, dataset)\n",
    "\n",
    "        self.train_file = os.path.join(self.path, dataset + TRAIN_SUFFIX)\n",
    "        self.validation_file = os.path.join(self.path, dataset + VALIDATION_SUFFIX)\n",
    "        self.test_file = os.path.join(self.path, dataset + TEST_SUFFIX)\n",
    "\n",
    "        self.info_file = os.path.join(self.path, dataset + INFO_SUFFIX)\n",
    "        self.user_file = os.path.join(self.path, dataset + USER_SUFFIX)\n",
    "        self.item_file = os.path.join(self.path, dataset + ITEM_SUFFIX)\n",
    "\n",
    "        self.train_pos_file = os.path.join(self.path, dataset + TRAIN_POS_SUFFIX)\n",
    "        self.validation_pos_file = os.path.join(self.path, dataset + VALIDATION_POS_SUFFIX)\n",
    "        self.test_pos_file = os.path.join(self.path, dataset + TEST_POS_SUFFIX)\n",
    "\n",
    "        self.train_neg_file = os.path.join(self.path, dataset + TRAIN_NEG_SUFFIX)\n",
    "        self.validation_neg_file = os.path.join(self.path, dataset + VALIDATION_NEG_SUFFIX)\n",
    "        self.test_neg_file = os.path.join(self.path, dataset + TEST_NEG_SUFFIX)\n",
    "\n",
    "        self.label = label\n",
    "\n",
    "        self.train_df, self.validation_df, self.test_df = None, None, None\n",
    "        self.load_user_item()\n",
    "        self.load_data()\n",
    "        self.load_his()\n",
    "        self.load_info()\n",
    "        # self.save_info()\n",
    "\n",
    "    def load_user_item(self):\n",
    "        self.user_df, self.item_df = None, None\n",
    "        if os.path.exists(self.user_file):\n",
    "            self.user_df = pd.read_csv(self.user_file, sep='\\t')\n",
    "        if os.path.exists(self.item_file):\n",
    "            self.item_df = pd.read_csv(self.item_file, sep='\\t')\n",
    "\n",
    "    def load_data(self):\n",
    "        self.train_df = pd.read_csv(self.train_file, sep='\\t')\n",
    "        self.validation_df = pd.read_csv(self.validation_file, sep='\\t')\n",
    "        self.test_df = pd.read_csv(self.test_file, sep='\\t')\n",
    "\n",
    "    def load_his(self):\n",
    "        # 把 df [uid, iids] 变成 dict {1: [iid, iid, ...] 2: [iid, iid, ...]}\n",
    "        def build_his(df):\n",
    "            uids = df['uid'].tolist()\n",
    "\n",
    "            iids = df['iids'].astype(str).str.split(',').values\n",
    "\n",
    "            iids = [[int(j) for j in i] for i in iids]\n",
    "            user_his = dict(zip(uids, iids))\n",
    "            return user_his\n",
    "\n",
    "        # 把 df [uid, iids] 变成 dict {1: [iid, iid, ...] 2: [iid, iid, ...]}\n",
    "        self.train_pos_df = pd.read_csv(self.train_pos_file, sep='\\t')\n",
    "        self.train_user_pos = build_his(self.train_pos_df)\n",
    "\n",
    "        self.validation_pos_df = pd.read_csv(self.validation_pos_file, sep='\\t')\n",
    "        self.validation_user_pos = build_his(self.validation_pos_df)\n",
    "\n",
    "        self.test_pos_df = pd.read_csv(self.test_pos_file, sep='\\t')\n",
    "        self.test_user_pos = build_his(self.test_pos_df)\n",
    "\n",
    "        self.train_neg_df = pd.read_csv(self.train_neg_file, sep='\\t')\n",
    "        self.train_user_neg = build_his(self.train_neg_df)\n",
    "\n",
    "        self.validation_neg_df = pd.read_csv(self.validation_neg_file, sep='\\t')\n",
    "        self.validation_user_neg = build_his(self.validation_neg_df)\n",
    "\n",
    "        self.test_neg_df = pd.read_csv(self.test_neg_file, sep='\\t')\n",
    "        self.test_user_neg = build_his(self.test_neg_df)\n",
    "\n",
    "    def append_his(self, max_his=10):\n",
    "        # 包含了 train, validation, test 中的所有的 uid 和 其对应的 iids\n",
    "        # 正样本是 iid, 负样本是 -iid\n",
    "        his_dict = {}\n",
    "\n",
    "        for df in [self.train_df, self.validation_df, self.test_df]:\n",
    "\n",
    "            history = []  # 最后加入到 df 中\n",
    "\n",
    "            uids, iids, labels = df['uid'].tolist(), df['iid'].tolist(), df['label'].tolist()\n",
    "\n",
    "            for i, uid in enumerate(uids):\n",
    "                iid, label = iids[i], labels[i]\n",
    "\n",
    "                if uid not in his_dict:\n",
    "                    his_dict[uid] = []\n",
    "\n",
    "                tmp_his = his_dict[uid] if max_his <= 0 else his_dict[uid][-max_his:]\n",
    "                #                 print(tmp_his)\n",
    "                # 去除 [] 第一个元素是 ‘’， history中的元素是 str 类型\n",
    "                history.append(str(tmp_his).replace(' ', '')[1:-1])\n",
    "\n",
    "                if label <= 0:\n",
    "                    his_dict[uid].append(-iid)\n",
    "                else:\n",
    "                    his_dict[uid].append(iid)\n",
    "            df['history'] = history\n",
    "\n",
    "    def load_info(self):\n",
    "        max_dict, min_dict = {}, {}\n",
    "        for df in [self.train_df, self.validation_df, self.test_df]:\n",
    "            for c in df.columns:\n",
    "                if c not in max_dict:\n",
    "                    max_dict[c] = df[c].max()\n",
    "                else:\n",
    "                    max_dict[c] = max(df[c].max(), max_dict[c])\n",
    "\n",
    "                if c not in min_dict:\n",
    "                    min_dict[c] = df[c].min()\n",
    "                else:\n",
    "                    min_dict[c] = min(df[c].min(), min_dict[c])\n",
    "\n",
    "        self.column_max = max_dict\n",
    "        self.column_min = min_dict\n",
    "\n",
    "        self.user_num, self.item_num = 0, 0\n",
    "        if 'uid' in self.column_max:\n",
    "            self.user_num = self.column_max['uid'] + 1\n",
    "        if 'iid' in self.column_max:\n",
    "            self.item_num = self.column_max['iid'] + 1\n",
    "\n",
    "    def drop_neg(self):\n",
    "        self.train_df = self.train_df[self.train_df['label'] > 0].reset_index(drop=True)\n",
    "        self.validation_df = self.validation_df[self.validation_df['label'] > 0].reset_index(drop=True)\n",
    "        self.test_df = self.test_df[self.test_df['label'] > 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "class DataProcessor(object):\n",
    "    data_columns = ['uid', 'iid', 'x']\n",
    "    info_columns = ['sample_id', 'time']\n",
    "\n",
    "    def __init__(self, data_loader):\n",
    "        self.data_loader = data_loader\n",
    "        #         self.train_sample_n = train_sample_n\n",
    "        #         self.test_sample_n = test_sample_n\n",
    "        self.train_data = None\n",
    "\n",
    "        self.pos_user_item_set = defaultdict(set)\n",
    "        for uid in data_loader.train_user_pos.keys():\n",
    "            self.pos_user_item_set[uid] = set(data_loader.train_user_pos[uid])\n",
    "\n",
    "        for uid in data_loader.validation_user_pos.keys():\n",
    "            if uid in self.pos_user_item_set:\n",
    "                self.pos_user_item_set[uid] = self.pos_user_item_set[uid] | set(data_loader.validation_user_pos[uid])\n",
    "            else:\n",
    "                self.pos_user_item_set[uid] = set(data_loader.validation_user_pos[uid])\n",
    "\n",
    "        for uid in data_loader.test_user_pos.keys():\n",
    "            if uid in self.pos_user_item_set:\n",
    "                self.pos_user_item_set[uid] = self.pos_user_item_set[uid] | set(data_loader.test_user_pos[uid])\n",
    "            else:\n",
    "                self.pos_user_item_set[uid] = set(data_loader.test_user_pos[uid])\n",
    "\n",
    "            \n",
    "        self.neg_user_item_set = defaultdict(set)\n",
    "        for uid in data_loader.train_user_neg.keys():\n",
    "            self.neg_user_item_set[uid] = set(data_loader.train_user_neg[uid])\n",
    "\n",
    "        for uid in data_loader.validation_user_neg.keys():\n",
    "            if uid in self.neg_user_item_set:\n",
    "                self.neg_user_item_set[uid] = self.neg_user_item_set[uid] | set(data_loader.validation_user_neg[uid])\n",
    "            else:\n",
    "                self.neg_user_item_set[uid] = set(data_loader.validation_user_neg[uid])\n",
    "\n",
    "        for uid in data_loader.test_user_neg.keys():\n",
    "            if uid in self.neg_user_item_set:\n",
    "                self.neg_user_item_set[uid] = self.neg_user_item_set[uid] | set(data_loader.test_user_neg[uid])\n",
    "            else:\n",
    "                self.neg_user_item_set[uid] = set(data_loader.test_user_neg[uid])\n",
    "\n",
    "    def prepare_batches(self, data, batch_size):\n",
    "        num_example = len(data['y'])\n",
    "\n",
    "        total_batch = int((num_example + batch_size - 1) / batch_size)\n",
    "\n",
    "        batches = []\n",
    "        for batch in tqdm(range(total_batch)):\n",
    "            batches.append(self.get_feed_dict(data=data, batch_start = batch * batch_size,\n",
    "                                              batch_size=batch_size))\n",
    "        return batches\n",
    "    \n",
    "    def numpy_to_torch(self, d, gpu=True, requires_grad=True):\n",
    "        t = torch.from_numpy(d)\n",
    "        if d.dtype is np.float:\n",
    "            t.requires_grad = requires_grad\n",
    "        if gpu and torch.cuda.device_count() > 0:\n",
    "            t = t.cuda()\n",
    "        return t\n",
    "\n",
    "    def get_feed_dict(self, data, batch_start, batch_size):\n",
    "        total_data_num = len(data['y'])\n",
    "        batch_end = min(len(data['y']), batch_start + batch_size)\n",
    "        real_batch_size = batch_end - batch_start\n",
    "\n",
    "        feed_dict = {\n",
    "            'real_batch_size': real_batch_size,\n",
    "            'x_sample_num': 5,\n",
    "        }\n",
    "        \n",
    "        feed_dict['y'] = self.numpy_to_torch(data['y'][batch_start:batch_start + real_batch_size])\n",
    "        \n",
    "        feed_dict['x'] = self.numpy_to_torch(data['x'][batch_start:batch_start + real_batch_size])\n",
    "        \n",
    "        feed_dict['iid'] = self.numpy_to_torch(data['iid'][batch_start:batch_start + real_batch_size])\n",
    "        \n",
    "        feed_dict['uid'] = self.numpy_to_torch(data['uid'][batch_start:batch_start + real_batch_size])\n",
    "        \n",
    "        return feed_dict\n",
    "\n",
    "        # x: batch_size, x_sample_num * 2\n",
    "        # iid\n",
    "        # uid\n",
    "\n",
    "    def get_validation_data(self):\n",
    "        df = self.generate_x_samples(self.data_loader.test_df)\n",
    "        self.test_data = self.format_data_dict(df)\n",
    "        return self.test_data\n",
    "\n",
    "    def get_test_data(self):\n",
    "        df = self.generate_x_samples(self.data_loader.validation_df)\n",
    "        self.validation_data = self.format_data_dict(df)\n",
    "        return self.validation_data\n",
    "\n",
    "    def get_train_data(self, epoch):\n",
    "        if self.train_data is None:\n",
    "            df = self.generate_x_samples(self.data_loader.train_df)\n",
    "            self.train_data = self.format_data_dict(df)\n",
    "        #             self.train_data['sample_id'] = np.arange(0, len(self.train_data['y']))\n",
    "\n",
    "        if epoch >= 0:\n",
    "            np.random.seed(10)  # 保证所有的column shuffle的顺序一样\n",
    "            rng_state = np.random.get_state()\n",
    "            for d in self.train_data:\n",
    "                np.random.set_state(rng_state)\n",
    "                np.random.shuffle(self.train_data[d])\n",
    "\n",
    "        return self.train_data\n",
    "\n",
    "    # 每个 uid iid 产生 5 个 正样本 和 5 个负样本\n",
    "    def generate_x_samples(self, df, x_number=5, stage='train'):\n",
    "        x_samples_list = []\n",
    "        idx_del = []\n",
    "\n",
    "        for i, uid in enumerate(df['uid'].values):\n",
    "\n",
    "            iid = df['iid'].values[i]\n",
    "\n",
    "            # get x_number positive samples\n",
    "            pos_iids = self.pos_user_item_set[uid]\n",
    "            if len(pos_iids) == 0:\n",
    "                idx_del.append(i)\n",
    "                continue\n",
    "            \n",
    "            if iid in pos_iids:\n",
    "                pos_iids.remove(iid)\n",
    "                if x_number < len(pos_iids):\n",
    "                    pos_samples = np.random.choice(list(pos_iids), x_number, replace=False)\n",
    "                else:\n",
    "                    pos_samples = np.random.choice(list(pos_iids), x_number, replace=True)\n",
    "                pos_iids.add(iid)\n",
    "            else:\n",
    "                if x_number < len(pos_iids):\n",
    "                    pos_samples = np.random.choice(list(pos_iids), x_number, replace=False)\n",
    "                else:\n",
    "                    pos_samples = np.random.choice(list(pos_iids), x_number, replace=True)\n",
    "\n",
    "            # get x_number negative samples (true negative and non-seen movies)\n",
    "            neg_samples = set()\n",
    "            for i in range(x_number):\n",
    "                neg_iid = np.random.randint(1, self.data_loader.item_num)\n",
    "                while neg_iid in neg_samples or neg_iid in pos_iids or neg_iid == iid:\n",
    "                    neg_iid = np.random.randint(1, self.data_loader.item_num)\n",
    "                neg_samples.add(neg_iid)\n",
    "            neg_samples = list(neg_samples)\n",
    "            \n",
    "            \n",
    "            x_samples = np.concatenate([pos_samples, neg_samples]).tolist()\n",
    "            x_samples_list.append(x_samples)\n",
    "            \n",
    "#         print('uid delete')\n",
    "#         for uid in uids_del:\n",
    "#             print(uid)\n",
    "        \n",
    "        df = df.drop(idx_del)\n",
    "        df['x'] = x_samples_list\n",
    "\n",
    "        return df\n",
    "\n",
    "    def format_data_dict(self, df):\n",
    "\n",
    "        #df = df[df['history'].apply(lambda x: len(x) > 0)]\n",
    "        data_loader = self.data_loader\n",
    "        data = {}\n",
    "\n",
    "        if 'uid' in df:\n",
    "            data['uid'] = df['uid'].values\n",
    "        if 'iid' in df:\n",
    "            data['iid'] = df['iid'].values\n",
    "        if 'time' in df:\n",
    "            data['time'] = df['time'].values\n",
    "        if 'label' in df:\n",
    "            data['y'] = np.array(df['label'], dtype=np.float32)\n",
    "        if 'x' in df:\n",
    "            data['x'] = np.array(df['x'].values.tolist())\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLoader = DataLoader('./dataset', 'ml100k01-1-5', 'label')\n",
    "dataprocessor = DataProcessor(dataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataprocessor.get_train_data(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 741/741 [00:00<00:00, 27369.33it/s]\n"
     ]
    }
   ],
   "source": [
    "batches = dataprocessor.prepare_batches(train_data, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'real_batch_size': 40,\n",
       " 'x_sample_num': 5,\n",
       " 'y': tensor([1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 0., 0.]),\n",
       " 'x': tensor([[ 316,  289,  511,  317,  607, 1157, 1480,  200,  855, 1305],\n",
       "         [ 511,   62,  133,  127,   56,  578, 1574, 1549, 1234,  375],\n",
       "         [ 272,  511,  268,  906,  321,  266,  749, 1075,  792, 1467],\n",
       "         [ 127,  690,   56,   62,  321,  449,  807,  872,   16,  470],\n",
       "         [  22,  132,  133,  887,  321, 1636,  170,   76,  598,  792],\n",
       "         [ 354,  333,  689,  362,  322,   97, 1638,  216,  348, 1565],\n",
       "         [ 305,  513,   56,  690,   22,   44,  282,  923, 1308, 1021],\n",
       "         [ 322,  689,  300,  362,  748,  609,  464, 1041, 1046, 1565],\n",
       "         [ 322,  300,  333,  748,  354,   64, 1247, 1583,  276,  607],\n",
       "         [ 272,  322,  333,  362,  354, 1508,  558,  724,  507, 1532],\n",
       "         [ 513,  127,  346,  315,  887,  867,  581,   71, 1174, 1017],\n",
       "         [ 347,  607,  305,  127,  289,  323, 1256, 1611, 1397, 1183],\n",
       "         [ 127,  187,  887,  588,  347,  640, 1444,  295,  105,  235],\n",
       "         [ 248,  513,  511,   62,  346, 1217, 1386,  175,  432,  597],\n",
       "         [ 133,  347,  127,  588,  272, 1570,  742,  520, 1613,  718],\n",
       "         [ 321,  340,  268,   62,  133, 1163,  761, 1205, 1625, 1087],\n",
       "         [ 588,  289,  690,  513,  133,  426, 1453,  879,  527,  670],\n",
       "         [ 607,   22,  690,  187,  132,  192, 1506,  306,  730,  669],\n",
       "         [ 305,  340,  690,  327,  315,  139,  142,  434,  338, 1529],\n",
       "         [ 248,  690,  272,  607,   62,  203, 1101, 1008,   59,  989],\n",
       "         [ 346,  268,  588,  132,   22,  553,  783,  404, 1172,  151],\n",
       "         [ 272,  748,  689,  354,  322,  255,   36,  847, 1526,  223],\n",
       "         [ 333,  748,  272,  354,  689, 1198,  463, 1619, 1561, 1532],\n",
       "         [ 513,  248,  289,  347,   22, 1287,   40,  103, 1364,  855],\n",
       "         [ 327,  132,  315,  127,  272,  352, 1215,  537,  637,  927],\n",
       "         [ 347,  906,  132,   56,   62, 1635,   39,  431, 1330, 1055],\n",
       "         [  56,  305,  268,  347,  906,  582, 1320,  332, 1262,  947],\n",
       "         [ 362,  333,  322,  748,  354, 1257, 1681,  822, 1110, 1016],\n",
       "         [ 362,  333,  748,  689,  272, 1615, 1522,  983, 1021, 1470],\n",
       "         [ 347,  302,  317,  272,  248, 1125,  779, 1328,  470,  637],\n",
       "         [ 511,  133,  268,  315,  327, 1349, 1254, 1037, 1142, 1631],\n",
       "         [ 302,  327,  289,  133,  588, 1472, 1418, 1646,  146,  602],\n",
       "         [ 333,  322,  272,  300,  748,  899,  869, 1317,  822, 1436],\n",
       "         [ 362,  689,  354,  300,  748,  260,  742,  658,  853,  413],\n",
       "         [ 333,  322,  272,  300,  354,  738,  900, 1007, 1462, 1311],\n",
       "         [ 272,  333,  362,  748,  354,  587,   18,  149, 1014,  251],\n",
       "         [ 748,  272,  362,  689,  300, 1640, 1617,  794,  443,  573],\n",
       "         [ 300,  333,  748,  272,  362,  165,  848,  466,  854, 1529],\n",
       "         [ 322,  272,  300,  689,  362,  672, 1569, 1573,  178,  564],\n",
       "         [ 333,  354,  748,  322,  362, 1317, 1425,  824,  701,  158]]),\n",
       " 'iid': tensor([ 327,  289,  887,  305,  268,  288,  906,  879,  751,  294,  325,  294,\n",
       "         1483,  911,  307,  306,  748,  354,  683,  346,   56,  338,  901,  127,\n",
       "          317,  187,  609,  683,  894,  472,  626,   22,  354,  322,  362,  300,\n",
       "          333,  689,  313,  328]),\n",
       " 'uid': tensor([683, 683, 683, 683, 683, 729, 683, 729, 729, 729, 683, 683, 683, 683,\n",
       "         683, 683, 683, 683, 683, 683, 683, 729, 729, 683, 683, 683, 683, 729,\n",
       "         729, 683, 683, 683, 729, 729, 729, 729, 729, 729, 729, 729])}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataLoader.train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24062</th>\n",
       "      <td>685</td>\n",
       "      <td>872</td>\n",
       "      <td>0</td>\n",
       "      <td>879447443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24063</th>\n",
       "      <td>685</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>879447443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24239</th>\n",
       "      <td>685</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>879451147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24240</th>\n",
       "      <td>685</td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>879451147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24242</th>\n",
       "      <td>685</td>\n",
       "      <td>334</td>\n",
       "      <td>0</td>\n",
       "      <td>879451168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24244</th>\n",
       "      <td>685</td>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>879451211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24245</th>\n",
       "      <td>685</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>879451234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24246</th>\n",
       "      <td>685</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>879451253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24247</th>\n",
       "      <td>685</td>\n",
       "      <td>991</td>\n",
       "      <td>0</td>\n",
       "      <td>879451282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24249</th>\n",
       "      <td>685</td>\n",
       "      <td>873</td>\n",
       "      <td>0</td>\n",
       "      <td>879451401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24250</th>\n",
       "      <td>685</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>879451401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24251</th>\n",
       "      <td>685</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>879451401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24252</th>\n",
       "      <td>685</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "      <td>879451401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24253</th>\n",
       "      <td>685</td>\n",
       "      <td>324</td>\n",
       "      <td>0</td>\n",
       "      <td>879451401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24254</th>\n",
       "      <td>685</td>\n",
       "      <td>340</td>\n",
       "      <td>0</td>\n",
       "      <td>879451401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24255</th>\n",
       "      <td>685</td>\n",
       "      <td>337</td>\n",
       "      <td>0</td>\n",
       "      <td>879451401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24256</th>\n",
       "      <td>685</td>\n",
       "      <td>882</td>\n",
       "      <td>0</td>\n",
       "      <td>879451401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24257</th>\n",
       "      <td>685</td>\n",
       "      <td>319</td>\n",
       "      <td>0</td>\n",
       "      <td>879451401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24258</th>\n",
       "      <td>685</td>\n",
       "      <td>875</td>\n",
       "      <td>0</td>\n",
       "      <td>879451401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24264</th>\n",
       "      <td>685</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>879451540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid  iid  label       time\n",
       "24062  685  872      0  879447443\n",
       "24063  685  286      0  879447443\n",
       "24239  685  333      0  879451147\n",
       "24240  685  288      0  879451147\n",
       "24242  685  334      0  879451168\n",
       "24244  685  886      0  879451211\n",
       "24245  685  327      0  879451234\n",
       "24246  685  289      0  879451253\n",
       "24247  685  991      0  879451282\n",
       "24249  685  873      0  879451401\n",
       "24250  685  325      0  879451401\n",
       "24251  685  302      0  879451401\n",
       "24252  685  269      0  879451401\n",
       "24253  685  324      0  879451401\n",
       "24254  685  340      0  879451401\n",
       "24255  685  337      0  879451401\n",
       "24256  685  882      0  879451401\n",
       "24257  685  319      0  879451401\n",
       "24258  685  875      0  879451401\n",
       "24264  685  299      0  879451540"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['uid'] == 685]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [uid, iid, label, time]\n",
       "Index: []"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df['uid'] == 685]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uid': 943, 'iid': 1682, 'label': 1, 'time': 893286638}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataLoader.column_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uid': 1, 'iid': 1, 'label': 0, 'time': 874724710}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataLoader.column_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1683"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataLoader.item_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "944"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataLoader.user_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = dataLoader.test_df\n",
    "validation_df = dataLoader.validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Object arrays cannot be loaded when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-2e3a0f8cb088>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./prediction.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./y.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./test_data.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch_test/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 453\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch_test/lib/python3.7/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0;31m# The array contained Python objects. We need to unpickle the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             raise ValueError(\"Object arrays cannot be loaded when \"\n\u001b[0m\u001b[1;32m    740\u001b[0m                              \"allow_pickle=False\")\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpickle_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "prediction = np.load('./prediction.npy')\n",
    "y = np.load('./y.npy')\n",
    "data = np.load('./test_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2253"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.where(prediction > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46515756768752775"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "accuracy_score(y, np.around(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids = np.array([1,1, 1, 1, 2, 2, 2, 3, 3, 3])\n",
    "p = np.array([0.5, 0.6, 0.7, 0.8, 0.7, 0.5, 0.6, 0.9, 0.7, 0.7])\n",
    "l = np.array([1, 1, 1, 0, 0, 0, 1, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = np.lexsort((-l, -p, uids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_uid = uids[sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_key, sorted_spl = np.unique(sorted_uid, return_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 7])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_l, sorted_p = l[sorted_idx], p[sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_l = np.split(sorted_l, sorted_spl[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_l_sum = [np.sum((d > 0).astype(float)) for d in split_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0, 1.0, 0.0, 0.0, 1.0, 2.0]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_l_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 1.]\n",
      "[0. 1. 0.]\n",
      "[0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "for d in split_l:\n",
    "    print((d > 0).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_data = [d[:3] for d in split_l]\n",
    "k_data_dict = defaultdict(list)\n",
    "for d in k_data:\n",
    "    k_data_dict[len(d)].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {3: [array([0, 1, 1]), array([0, 1, 0]), array([0, 1, 1])]})"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = [np.average((np.array(d) > 0).astype(float), axis=1) for d in k_data_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5555555555555555"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(np.concatenate(precisions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('./Thesis_Test.xlsx', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Image', 'Gender', 'Emotion', 'Race', 'Age'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_images_from_dir(image_dir):\n",
    "    image_dir = Path(image_dir)\n",
    "    for image_path in image_dir.glob(\"*.jpg\"):\n",
    "        img = cv2.imread(str(image_path))\n",
    "        if img is not None:\n",
    "            h, w, _ = img.shape\n",
    "            r = 640/max(w, h)\n",
    "            yield cv2.resize(img, (int(w * r), int(h * r))), str(image_path)\n",
    "\n",
    "def draw_label(image, point, label, font=cv2.FONT_HERSHEY_SIMPLEX, font_scale=0.8, thickness=1):\n",
    "    size = cv2.getTextSize(label, font, font_scale, thickness)[0]\n",
    "    x, y = point\n",
    "    cv2.rectangle(image, (x, y-size[1]), (x + size[0], y), (255, 0, 0), cv2.FILLED)\n",
    "    cv2.putText(image, label, point, font, font_scale, (255, 255, 255), thickness, lineType=cv2.LINE_AA)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_generator = yield_images_from_dir('./Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Images/001818.jpg\n",
      "Successgully saved\n",
      "./Images/001597.jpg\n",
      "Successgully saved\n",
      "./Images/001557.jpg\n",
      "Successgully saved\n",
      "./Images/18500461.jpg\n",
      "Successgully saved\n",
      "./Images/001487.jpg\n",
      "Successgully saved\n"
     ]
    }
   ],
   "source": [
    "for img, path in img_generator:\n",
    "    input_img = img\n",
    "    img_name = path.split('/')[-1]\n",
    "    age = df[df['Image']==img_name]['Age'].values[0]\n",
    "    gender = df[df['Image']==img_name]['Gender'].values[0]\n",
    "    emotion = df[df['Image'] == img_name]['Emotion'].values[0]\n",
    "    race = df[df['Image'] == img_name]['Race'].values[0]\n",
    "    \n",
    "    label = \"{}, {}, {}, {}\".format(age, gender, emotion, race)\n",
    "    draw_label(input_img, (20, 20), label)\n",
    "    \n",
    "    print('./Images/' + img_name)\n",
    "    cv2.imwrite('./Images/' + img_name, input_img)\n",
    "    print('Successgully saved')\n",
    "#     cv2.imshow('window', input_img)\n",
    "#     cv2.waitKey(0)\n",
    "    \n",
    "# cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
