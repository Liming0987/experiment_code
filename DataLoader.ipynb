{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "TRAIN_SUFFIX = '.train.csv'\n",
    "VALIDATION_SUFFIX = '.validation.csv'\n",
    "TEST_SUFFIX = '.test.csv'  # 测试集文件后缀\n",
    "\n",
    "INFO_SUFFIX = '.info.json'  # 数据集统计信息文件后缀\n",
    "USER_SUFFIX = '.user.csv'  # 数据集用户特征文件后缀\n",
    "ITEM_SUFFIX = '.item.csv'  # 数据集物品特征文件后缀\n",
    "\n",
    "TRAIN_POS_SUFFIX = '.train_pos.csv'  # 训练集用户正向交互按uid合并之后的文件后缀\n",
    "VALIDATION_POS_SUFFIX = '.validation_pos.csv'  # 验证集用户正向交互按uid合并之后的文件后缀\n",
    "TEST_POS_SUFFIX = '.test_pos.csv'  # 测试集用户正向交互按uid合并之后的文件后缀\n",
    "\n",
    "TRAIN_NEG_SUFFIX = '.train_neg.csv'  # 训练集用户负向交互按uid合并之后的文件后缀\n",
    "VALIDATION_NEG_SUFFIX = '.validation_neg.csv'  # 验证集用户负向交互按uid合并之后的文件后缀\n",
    "TEST_NEG_SUFFIX = '.test_neg.csv'  # 测试集用户负向交互按uid合并之后的文件后缀\n",
    "\n",
    "class DataLoader(object):\n",
    "    \n",
    "    def __init__(self, path, dataset, label, sep='\\t'):\n",
    "        self.dataset = dataset\n",
    "        self.path = os.path.join(path, dataset)\n",
    "        \n",
    "        self.train_file = os.path.join(self.path, dataset + TRAIN_SUFFIX)\n",
    "        self.validation_file = os.path.join(self.path, dataset + VALIDATION_SUFFIX)\n",
    "        self.test_file = os.path.join(self.path, dataset + TEST_SUFFIX)\n",
    "        \n",
    "        self.info_file = os.path.join(self.path, dataset + INFO_SUFFIX)\n",
    "        self.user_file = os.path.join(self.path, dataset + USER_SUFFIX)\n",
    "        self.item_file = os.path.join(self.path, dataset + ITEM_SUFFIX)\n",
    "        \n",
    "        self.train_pos_file = os.path.join(self.path, dataset + TRAIN_POS_SUFFIX)\n",
    "        self.validation_pos_file = os.path.join(self.path, dataset + VALIDATION_POS_SUFFIX)\n",
    "        self.test_pos_file = os.path.join(self.path, dataset + TEST_POS_SUFFIX)\n",
    "        \n",
    "        self.train_neg_file = os.path.join(self.path, dataset + TRAIN_NEG_SUFFIX)\n",
    "        self.validation_neg_file = os.path.join(self.path, dataset + VALIDATION_NEG_SUFFIX)\n",
    "        self.test_neg_file = os.path.join(self.path, dataset + TEST_NEG_SUFFIX)\n",
    "        \n",
    "        self.label = label\n",
    "        \n",
    "        self.train_df, self.validation_df, self.test_df = None, None, None\n",
    "        self.load_user_item()\n",
    "        self.load_data()\n",
    "        self.load_his()\n",
    "        self.load_info()\n",
    "        #self.save_info()\n",
    "    \n",
    "    def load_user_item(self):\n",
    "        self.user_df, self.item_df = None, None\n",
    "        if os.path.exists(self.user_file):\n",
    "            self.user_df = pd.read_csv(self.user_file, sep='\\t')\n",
    "        if os.path.exists(self.item_file):\n",
    "            self.item_df = pd.read_csv(self.item_file, sep='\\t')\n",
    "        \n",
    "    def load_data(self):\n",
    "        self.train_df = pd.read_csv(self.train_file, sep='\\t')\n",
    "        self.validation_df = pd.read_csv(self.validation_file, sep='\\t')\n",
    "        self.test_df = pd.read_csv(self.test_file, sep='\\t')\n",
    "        \n",
    "    def load_his(self):\n",
    "        # 把 df [uid, iids] 变成 dict {1: [iid, iid, ...] 2: [iid, iid, ...]}\n",
    "        def build_his(df):\n",
    "            uids = df['uid'].tolist()\n",
    "            \n",
    "            iids = df['iids'].astype(str).str.split(',').values\n",
    "            \n",
    "            iids = [[int(j) for j in i] for i in iids]\n",
    "            user_his = dict(zip(uids, iids))\n",
    "            return user_his\n",
    "        # 把 df [uid, iids] 变成 dict {1: [iid, iid, ...] 2: [iid, iid, ...]}\n",
    "        self.train_pos_df = pd.read_csv(self.train_pos_file, sep='\\t')\n",
    "        self.train_user_pos = build_his(self.train_pos_df)\n",
    "        \n",
    "        self.validation_pos_df = pd.read_csv(self.validation_pos_file, sep='\\t')\n",
    "        self.validation_user_pos = build_his(self.validation_pos_df)\n",
    "        \n",
    "        self.test_pos_df = pd.read_csv(self.test_pos_file, sep='\\t')\n",
    "        self.test_user_pos = build_his(self.test_pos_df)\n",
    "        \n",
    "        self.train_neg_df = pd.read_csv(self.train_neg_file, sep='\\t')\n",
    "        self.train_user_neg = build_his(self.train_neg_df)\n",
    "        \n",
    "        self.validation_neg_df = pd.read_csv(self.validation_neg_file, sep='\\t')\n",
    "        self.validation_user_neg = build_his(self.validation_neg_df)\n",
    "        \n",
    "        self.test_neg_df = pd.read_csv(self.test_neg_file, sep='\\t')\n",
    "        self.test_user_neg = build_his(self.test_neg_df)\n",
    "        \n",
    "    def append_his(self, max_his=10):\n",
    "        # 包含了 train, validation, test 中的所有的 uid 和 其对应的 iids\n",
    "        # 正样本是 iid, 负样本是 -iid\n",
    "        his_dict = {}\n",
    "        \n",
    "        for df in [self.train_df, self.validation_df, self.test_df]:\n",
    "            \n",
    "            history = [] # 最后加入到 df 中\n",
    "            \n",
    "            uids, iids, labels = df['uid'].tolist(), df['iid'].tolist(), df['label'].tolist()\n",
    "            \n",
    "            for i, uid in enumerate(uids):\n",
    "                iid, label = iids[i], labels[i]\n",
    "                \n",
    "                if uid not in his_dict:\n",
    "                    his_dict[uid] = []\n",
    "                \n",
    "                tmp_his = his_dict[uid] if max_his <= 0 else his_dict[uid][-max_his:]\n",
    "#                 print(tmp_his)\n",
    "                # 去除 [] 第一个元素是 ‘’， history中的元素是 str 类型\n",
    "                history.append(str(tmp_his).replace(' ', '')[1:-1])\n",
    "                \n",
    "                if label <= 0:\n",
    "                    his_dict[uid].append(-iid)\n",
    "                else:\n",
    "                    his_dict[uid].append(iid)\n",
    "            df['history'] = history\n",
    "    def load_info(self):\n",
    "        max_dict, min_dict = {}, {}\n",
    "        for df in [self.train_df, self.validation_df, self.test_df]:\n",
    "            for c in df.columns:\n",
    "                if c not in max_dict:\n",
    "                    max_dict[c] = df[c].max()\n",
    "                else:\n",
    "                    max_dict[c] = max(df[c].max(), max_dict[c])\n",
    "                \n",
    "                if c not in min_dict:\n",
    "                    min_dict[c] = df[c].min()\n",
    "                else:\n",
    "                    min_dict[c] = min(df[c].min(), min_dict[c])\n",
    "                \n",
    "        self.column_max = max_dict\n",
    "        self.column_min = min_dict\n",
    "        \n",
    "        self.user_num, self.item_num = 0, 0\n",
    "        if 'uid' in self.column_max:\n",
    "            self.user_num = self.column_max['uid'] + 1\n",
    "        if 'iid' in self.column_max:\n",
    "            self.item_num = self.column_max['iid'] + 1\n",
    "        \n",
    "                    \n",
    "    def drop_neg(self):\n",
    "        self.train_df = self.train_df[self.train_df['label'] > 0].reset_index(drop=True)\n",
    "        self.validation_df = self.validation_df[self.validation_df['label'] > 0].reset_index(drop=True)\n",
    "        self.test_df = self.test_df[self.test_df['label'] > 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader('./dataset', 'ml100k01-1-5', 'label')\n",
    "# dataloader.append_his()\n",
    "# dataloader.drop_neg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    53514\n",
       "0    41266\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor(object):\n",
    "    data_columns = ['uid', 'iid', 'x']\n",
    "    info_columns = ['sample_id', 'time']\n",
    "    \n",
    "    def __init__(self, data_loader):\n",
    "        self.data_loader = data_loader\n",
    "#         self.train_sample_n = train_sample_n\n",
    "#         self.test_sample_n = test_sample_n\n",
    "        self.train_data = None\n",
    "        \n",
    "        self.train_history_pos = defaultdict(set)\n",
    "        for uid in data_loader.train_user_pos.keys():\n",
    "            self.train_history_pos[uid] = set(data_loader.train_user_pos[uid])\n",
    "            \n",
    "        self.validation_history_pos = defaultdict(set)\n",
    "        for uid in data_loader.validation_user_pos.keys():\n",
    "            self.validation_history_pos[uid] = set(data_loader.validation_user_pos[uid])\n",
    "\n",
    "        self.test_history_pos = defaultdict(set)\n",
    "        for uid in data_loader.test_user_pos.keys():\n",
    "            self.test_history_pos[uid] = set(data_loader.test_user_pos[uid])\n",
    "\n",
    "        self.train_history_neg = defaultdict(set)\n",
    "        for uid in data_loader.train_user_neg.keys():\n",
    "            self.train_history_neg[uid] = set(data_loader.train_user_neg[uid])\n",
    "\n",
    "        self.validation_history_neg = defaultdict(set)\n",
    "        for uid in data_loader.validation_user_neg.keys():\n",
    "            self.validation_history_neg[uid] = set(data_loader.validation_user_neg[uid])\n",
    "\n",
    "        self.test_history_neg = defaultdict(set)\n",
    "        for uid in data_loader.test_user_neg.keys():\n",
    "            self.test_history_neg[uid] = set(data_loader.test_user_neg[uid])\n",
    "        \n",
    "    def get_train_data(self, epoch):\n",
    "        if self.train_data is None:\n",
    "            self.generate_x_samples(self.data_loader.train_df)\n",
    "#             self.train_data = self.format_data_dict(self.data_loader.train_df)\n",
    "#             self.train_data['sample_id'] = np.arange(0, len(self.train_data['y']))\n",
    "        \n",
    "        if epoch >= 0:\n",
    "            np.random.seed(10) # 保证所有的column shuffle的顺序一样\n",
    "            rng_state = np.random.get_state()\n",
    "            for d in self.train_data:\n",
    "                np.random.set_state(rng_state)\n",
    "                np.random.shuffle(self.train_data[d])\n",
    "                \n",
    "#         return self.train_data\n",
    "    \n",
    "    # 每个 uid iid 产生 5 个 正样本 和 5 个负样本\n",
    "    def generate_x_samples(self, df, x_number=5, stage='train'):\n",
    "        x_samples_list = []\n",
    "        \n",
    "        if stage == 'train':\n",
    "            user_pos = self.train_history_pos\n",
    "            user_neg = self.train_history_neg\n",
    "        elif stage == 'validation':\n",
    "            user_pos = self.validation_history_pos\n",
    "            user_neg = self.validation_history_neg\n",
    "        elif stage == 'test':\n",
    "            user_pos = self.test_history_pos\n",
    "            user_neg = self.test_history_neg\n",
    "            \n",
    "        for i, uid in enumerate(df['uid'].values):\n",
    "\n",
    "            iid = df['iid'].values[i]\n",
    "            \n",
    "            # get x_number positive samples\n",
    "            pos_iids = user_pos[uid]\n",
    "            if iid in pos_iids:\n",
    "                pos_iids.remove(iid)\n",
    "                if x_number < len(pos_iids):\n",
    "                    pos_samples = np.random.choice(list(pos_iids), x_number, replace=False)\n",
    "                else:\n",
    "                    pos_samples = np.random.choice(list(pos_iids), x_number, replace=True)\n",
    "                pos_iids.add(iid)\n",
    "            else:\n",
    "                if x_number < len(pos_iids):\n",
    "                    pos_samples = np.random.choice(list(pos_iids), x_number, replace=False)\n",
    "                else:\n",
    "                    pos_samples = np.random.choice(list(pos_iids), x_number, replace=True)\n",
    "                pos_iids.add(iid)\n",
    "            \n",
    "            # get x_number negative samples\n",
    "            neg_iids = user_neg[uid]\n",
    "            if iid in neg_iids:\n",
    "                neg_iids.remove(iid)\n",
    "                if x_number < len(neg_iids):\n",
    "                    neg_samples = np.random.choice(list(neg_iids), x_number, replace=False)\n",
    "                else:\n",
    "                    neg_samples = np.random.choice(list(neg_iids), x_number, replace=True)\n",
    "                neg_iids.add(iid)\n",
    "            else:\n",
    "                if x_number < len(neg_iids):\n",
    "                    neg_samples = np.random.choice(list(neg_iids), x_number, replace=False)\n",
    "                else:\n",
    "                    neg_samples = np.random.choice(list(neg_iids), x_number, replace=True)\n",
    "                neg_iids.add(iid)\n",
    "\n",
    "            x_samples = np.concatenate([pos_samples, neg_samples]).tolist()\n",
    "            x_samples_list.append(x_samples)\n",
    "\n",
    "        df['x'] = x_samples_list\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def format_data_dict(self, df):\n",
    "        \n",
    "#         df = df[df['history'].apply(lambda x: len(x) > 0)]\n",
    "        \n",
    "        data_loader = self.data_loader\n",
    "        data = {}\n",
    "        \n",
    "        if 'uid' in df:\n",
    "            data['uid'] = df['uid'].values\n",
    "        if 'iid' in df:\n",
    "            data['iid'] = df['iid'].values\n",
    "        if 'time' in df:\n",
    "            data['time'] = df['time'].values\n",
    "        if 'label' in df:\n",
    "            data['y'] = np.array(df['label'], dtype=np.float32)\n",
    "        \n",
    "\n",
    "            \n",
    "    \n",
    "    # data 是 format_data_dict 处理后的字典\n",
    "    def prepare_batches(self, data, batch_size, train):\n",
    "        num_example = len(data['y'])\n",
    "        total_batch = int((num_example + batch_size - 1)/batch_size)\n",
    "        neg_data = None\n",
    "        if train:\n",
    "            neg_data = self.generate_neg_data(data, \n",
    "                                              self.data_loader.train_df, \n",
    "                                              sample_n=self.train_sample_n,\n",
    "                                              train=True)\n",
    "        batches = []\n",
    "        \n",
    "        for batch in tqdm(range(total_batch), leave=False, ncols=100, mininterval=1, desc='Prepare Batches'):\n",
    "            batches.append(self.get_feed_dict(data=data, batch_start=batch * batch_size, batch_size= batch_size,\n",
    "                                             train=train, neg_data=neg_data))\n",
    "            \n",
    "        return batches\n",
    "    \n",
    "    def get_feed_dict(self, data, batch_start, batch_size, train, neg_data=None):\n",
    "        \n",
    "        total_data_num = len(data['sample_id'])\n",
    "        batch_end = min(len(data['uid']), batch_start + batch_size)\n",
    "        real_batch_size = batch_end - batch_start\n",
    "        total_batch_size = real_batch_size * (self.train_sample_n + 1)\n",
    "        \n",
    "        feed_dict = {'train': train, 'real_batch_size': real_batch_size, 'total_batch_size': total_batch_size}\n",
    "        \n",
    "        feed_dict['y'] = self.numpy_to_torch(data['y'][batch_start:batch_start + real_batch_size])\n",
    "        for c in ['uid', 'iid', 'x', 'sample_id', 'time', 'history']:\n",
    "            d = data[c][batch_start: batch_start + real_batch_size]\n",
    "            if train:\n",
    "                neg_d = np.concatenate([neg_data[c][total_data_num * i + batch_start: total_data_num * i + batch_start + real_batch_size]\n",
    "                                       for i in range(self.train_sample_n)])\n",
    "        \n",
    "                d = np.concatenate([d, neg_d])\n",
    "            feed_dict[c] = d\n",
    "        \n",
    "        for c in ['uid', 'iid', 'x', 'history']:\n",
    "            feed_dict[c] = self.numpy_to_torch(feed_dict[c])\n",
    "        \n",
    "        return feed_dict\n",
    "        \n",
    "    def numpy_to_torch(self, d, gpu=False, requires_grad=True):\n",
    "        t = torch.from_numpy(d)\n",
    "        if d.dtype is np.float:\n",
    "            t.requires_grad = requires_grad\n",
    "        if gpu and torch.cuda.device_count() > 0:\n",
    "            t = t.cuda()\n",
    "        return t\n",
    "        \n",
    "        # 确保每个feature值都对应一个独特的 value\n",
    "#         base = 0\n",
    "#         for feature in ui_id.columns:\n",
    "#             ui_id[feature] = ui_id[feature].apply(lambda x: x + base)\n",
    "#             base += int(data_loader.column_max[feature] + 1)\n",
    "        \n",
    "#         data['x'] = ui_id.values.astype(int)\n",
    "        \n",
    "        # 把字符串转化成 list\n",
    "#         data['history'] = df['history'].apply(lambda x: eval('[' + x + ']'))\n",
    "        return data\n",
    "    \n",
    "#     def generate_neg_data(self, data, feature_df, sample_n, train):\n",
    "#         inter_df = pd.DataFrame()\n",
    "#         for c in ['uid', 'iid', 'y', 'time']:\n",
    "#             if c in data:\n",
    "#                 inter_df[c] = data[c]\n",
    "        \n",
    "#         neg_df = self.generate_neg_df(inter_df=inter_df,\n",
    "#                                      feature_df=feature_df,\n",
    "#                                      sample_n=sample_n, train=train)\n",
    "        \n",
    "#         neg_data = self.format_data_dict(neg_df)\n",
    "        \n",
    "# #         neg_data['sample_id'] = np.arange(0, len(neg_data['y'])) + len(data['sample_id'])\n",
    "        \n",
    "#         return neg_data\n",
    "                                          \n",
    "    \n",
    "#     def generate_neg_df(self, inter_df, feature_df, sample_n, train):\n",
    "#         other_columns = [c for c in inter_df.columns if c not in ['uid', 'y']]\n",
    "        \n",
    "#         neg_df = self._sample_neg_from_uid_list(uids=inter_df['uid'].tolist(),\n",
    "#                                                labels=inter_df['y'].tolist(),\n",
    "#                                                sample_n=sample_n,\n",
    "#                                                train=train,\n",
    "#                                                 # other_infos : {'iid', [], 'time': []}\n",
    "#                                                other_infos=inter_df[other_columns].to_dict('list'))\n",
    "#         # neg_df 和 train_df 具有相同的 history\n",
    "#         neg_df = pd.merge(neg_df, feature_df, on=['uid'] + other_columns, how='left')\n",
    "        \n",
    "#         neg_df = neg_df.drop(columns=['iid'])\n",
    "#         neg_df = neg_df.rename(columns={'iid_neg': 'iid'})\n",
    "        \n",
    "#         neg_df = neg_df[feature_df.columns]\n",
    "#         neg_df['label'] = 0\n",
    "#         return neg_df\n",
    "    \n",
    "#     def _sample_neg_from_uid_list(self, uids, labels, sample_n, train, other_infos):\n",
    "        \n",
    "#         # 负样本集合，一个uid对应一个 unknown_iid_list\n",
    "#         iid_list = []\n",
    "        \n",
    "#         other_info_list = {}\n",
    "#         for info in other_infos:\n",
    "#             other_info_list[info] = []\n",
    "        \n",
    "#         item_num = self.data_loader.item_num\n",
    "#         for index, uid in enumerate(uids):\n",
    "#             if labels[index] > 0:\n",
    "#                 train_history = self.train_history_pos\n",
    "#                 validation_hisotry, test_history = self.validation_history_pos, self.test_history_pos\n",
    "#                 known_train = self.train_history_neg\n",
    "#             else:\n",
    "#                 assert train #?\n",
    "#                 train_history = self.train_history_neg\n",
    "#                 validation_hisotry, test_history = self.validation_history_neg, self.test_history_neg\n",
    "#                 known_train = self.train_history_pos\n",
    "            \n",
    "#             if train:\n",
    "#                 inter_iids = train_history[uid]\n",
    "#             else:\n",
    "#                 inter_iids = train_history[uid] | validation_hisotry[uid] | test_history[uid]\n",
    "            \n",
    "#             remain_iids_num = item_num - len(inter_iids)\n",
    "            \n",
    "#             sampled = set()\n",
    "#             unknown_iid_list = []\n",
    "#             for i in range(sample_n):\n",
    "#                 iid = np.random.randint(1, self, data_loader.item_num)\n",
    "#                 while iid in inter_iids or iid in sampled:\n",
    "#                     iid = np.random.randint(1, self.data_loader.item_num)\n",
    "#                 unknown_iid_list.append(iid)\n",
    "#                 sampled.add(iid)\n",
    "            \n",
    "#             iid_list.append(unknown_iid_list)\n",
    "            \n",
    "#         all_uid_list, all_iid_list = [], []\n",
    "#         for i in range(sample_n):\n",
    "#             for index, uid in enumerate(uids):\n",
    "#                 all_uid_list.append(uid)\n",
    "#                 all_iid_list.append(iid_list[index][i])\n",
    "            \n",
    "#             for info in other_infos:\n",
    "#                 other_info_list[info].append(other_infos[info][index])\n",
    "       \n",
    "#         neg_df = pd.DataFrame(data=list(zip(all_uid_list, all_iid_list)), columns=['uid', 'iid_neg'])\n",
    "#         for info in other_infos:\n",
    "#             neg_df[info] = other_info_list[info]\n",
    "#         return neg_df\n",
    "            \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor(object):\n",
    "    data_columns = ['uid', 'iid', 'x']\n",
    "    info_columns = ['sample_id', 'time']\n",
    "    \n",
    "    def __init__(self, data_loader):\n",
    "        self.data_loader = data_loader\n",
    "#         self.train_sample_n = train_sample_n\n",
    "#         self.test_sample_n = test_sample_n\n",
    "        self.train_data = None\n",
    "        \n",
    "        self.train_history_pos = defaultdict(set)\n",
    "        for uid in data_loader.train_user_pos.keys():\n",
    "            self.train_history_pos[uid] = set(data_loader.train_user_pos[uid])\n",
    "            \n",
    "        self.validation_history_pos = defaultdict(set)\n",
    "        for uid in data_loader.validation_user_pos.keys():\n",
    "            self.validation_history_pos[uid] = set(data_loader.validation_user_pos[uid])\n",
    "\n",
    "        self.test_history_pos = defaultdict(set)\n",
    "        for uid in data_loader.test_user_pos.keys():\n",
    "            self.test_history_pos[uid] = set(data_loader.test_user_pos[uid])\n",
    "\n",
    "        self.train_history_neg = defaultdict(set)\n",
    "        for uid in data_loader.train_user_neg.keys():\n",
    "            self.train_history_neg[uid] = set(data_loader.train_user_neg[uid])\n",
    "\n",
    "        self.validation_history_neg = defaultdict(set)\n",
    "        for uid in data_loader.validation_user_neg.keys():\n",
    "            self.validation_history_neg[uid] = set(data_loader.validation_user_neg[uid])\n",
    "\n",
    "        self.test_history_neg = defaultdict(set)\n",
    "        for uid in data_loader.test_user_neg.keys():\n",
    "            self.test_history_neg[uid] = set(data_loader.test_user_neg[uid])\n",
    "        \n",
    "    def get_train_data(self, epoch):\n",
    "        if self.train_data is None:\n",
    "            self.generate_x_samples(self.data_loader.train_df)\n",
    "#             self.train_data = self.format_data_dict(self.data_loader.train_df)\n",
    "#             self.train_data['sample_id'] = np.arange(0, len(self.train_data['y']))\n",
    "        \n",
    "        if epoch >= 0:\n",
    "            np.random.seed(10) # 保证所有的column shuffle的顺序一样\n",
    "            rng_state = np.random.get_state()\n",
    "            for d in self.train_data:\n",
    "                np.random.set_state(rng_state)\n",
    "                np.random.shuffle(self.train_data[d])\n",
    "                \n",
    "#         return self.train_data\n",
    "    \n",
    "    # 每个 uid iid 产生 5 个 正样本 和 5 个负样本\n",
    "    def generate_x_samples(self, df, x_number=5, stage='train'):\n",
    "        x_samples_list = []\n",
    "        \n",
    "        if stage == 'train':\n",
    "            user_pos = self.train_history_pos\n",
    "            user_neg = self.train_history_neg\n",
    "        elif stage == 'validation':\n",
    "            user_pos = self.validation_history_pos\n",
    "            user_neg = self.validation_history_neg\n",
    "        elif stage == 'test':\n",
    "            user_pos = self.test_history_pos\n",
    "            user_neg = self.test_history_neg\n",
    "            \n",
    "        for i, uid in enumerate(df['uid'].values):\n",
    "\n",
    "            iid = df['iid'].values[i]\n",
    "            \n",
    "            # get x_number positive samples\n",
    "            pos_iids = user_pos[uid]\n",
    "            if iid in pos_iids:\n",
    "                pos_iids.remove(iid)\n",
    "                if x_number < len(pos_iids):\n",
    "                    pos_samples = np.random.choice(list(pos_iids), x_number, replace=False)\n",
    "                else:\n",
    "                    pos_samples = np.random.choice(list(pos_iids), x_number, replace=True)\n",
    "                pos_iids.add(iid)\n",
    "            else:\n",
    "                if x_number < len(pos_iids):\n",
    "                    pos_samples = np.random.choice(list(pos_iids), x_number, replace=False)\n",
    "                else:\n",
    "                    pos_samples = np.random.choice(list(pos_iids), x_number, replace=True)\n",
    "            \n",
    "            # get x_number negative samples (true negative and non-seen movies)\n",
    "            neg_iids = user_neg[uid]\n",
    "            if iid in neg_iids:\n",
    "                neg_iids.remove(iid)\n",
    "                if x_number < len(neg_iids):\n",
    "                    neg_samples = np.random.choice(list(neg_iids), x_number, replace=False)\n",
    "                else:\n",
    "                    \n",
    "                neg_iids.add(iid)\n",
    "            else:\n",
    "                if x_number < len(neg_iids):\n",
    "                    neg_samples = np.random.choice(list(neg_iids), x_number, replace=False)\n",
    "                else:\n",
    "                    print(uid)\n",
    "                    neg_samples = np.random.choice(list(neg_iids), x_number, replace=True)\n",
    "\n",
    "            x_samples = np.concatenate([pos_samples, neg_samples]).tolist()\n",
    "            x_samples_list.append(x_samples)\n",
    "\n",
    "        df['x'] = x_samples_list\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def format_data_dict(self, df):\n",
    "        \n",
    "#         df = df[df['history'].apply(lambda x: len(x) > 0)]\n",
    "        \n",
    "        data_loader = self.data_loader\n",
    "        data = {}\n",
    "        \n",
    "        if 'uid' in df:\n",
    "            data['uid'] = df['uid'].values\n",
    "        if 'iid' in df:\n",
    "            data['iid'] = df['iid'].values\n",
    "        if 'time' in df:\n",
    "            data['time'] = df['time'].values\n",
    "        if 'label' in df:\n",
    "            data['y'] = np.array(df['label'], dtype=np.float32)\n",
    "    \n",
    "    def prepare_batches():\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataprocessor = DataProcessor(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941\n",
      "941\n",
      "941\n",
      "941\n",
      "941\n",
      "941\n",
      "941\n",
      "941\n",
      "941\n",
      "941\n",
      "941\n",
      "941\n",
      "941\n",
      "941\n",
      "941\n",
      "941\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "118\n",
      "477\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'a' cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-376-e7000da11372>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# dataprocessor.prepare_batches(train_data, 128, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-374-b48f848e39f7>\u001b[0m in \u001b[0;36mget_train_data\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_x_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;31m#             self.train_data = self.format_data_dict(self.data_loader.train_df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m#             self.train_data['sample_id'] = np.arange(0, len(self.train_data['y']))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-374-b48f848e39f7>\u001b[0m in \u001b[0;36mgenerate_x_samples\u001b[0;34m(self, df, x_number, stage)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                     \u001b[0mneg_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_iids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mx_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "dataprocessor.get_train_data(-1)\n",
    "# dataprocessor.prepare_batches(train_data, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history_pos = defaultdict(set)\n",
    "for uid in dataloader.train_user_neg.keys():\n",
    "    train_history_pos[uid] = set(dataloader.train_user_neg[uid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_history_pos[477]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7863</th>\n",
       "      <td>477</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>875940451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7864</th>\n",
       "      <td>477</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>875940693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7865</th>\n",
       "      <td>477</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>875940755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7866</th>\n",
       "      <td>477</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>875940755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7867</th>\n",
       "      <td>477</td>\n",
       "      <td>369</td>\n",
       "      <td>1</td>\n",
       "      <td>875940836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7868</th>\n",
       "      <td>477</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>875941022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7869</th>\n",
       "      <td>477</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>875941085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7870</th>\n",
       "      <td>477</td>\n",
       "      <td>724</td>\n",
       "      <td>1</td>\n",
       "      <td>875941086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7871</th>\n",
       "      <td>477</td>\n",
       "      <td>732</td>\n",
       "      <td>1</td>\n",
       "      <td>875941111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7872</th>\n",
       "      <td>477</td>\n",
       "      <td>794</td>\n",
       "      <td>1</td>\n",
       "      <td>875941111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7873</th>\n",
       "      <td>477</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>875941155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7874</th>\n",
       "      <td>477</td>\n",
       "      <td>553</td>\n",
       "      <td>1</td>\n",
       "      <td>875941155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7875</th>\n",
       "      <td>477</td>\n",
       "      <td>739</td>\n",
       "      <td>1</td>\n",
       "      <td>875941191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7876</th>\n",
       "      <td>477</td>\n",
       "      <td>778</td>\n",
       "      <td>1</td>\n",
       "      <td>875941191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7877</th>\n",
       "      <td>477</td>\n",
       "      <td>781</td>\n",
       "      <td>1</td>\n",
       "      <td>875941191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7878</th>\n",
       "      <td>477</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>875941224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7879</th>\n",
       "      <td>477</td>\n",
       "      <td>1041</td>\n",
       "      <td>1</td>\n",
       "      <td>875941225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7880</th>\n",
       "      <td>477</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>875941275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7881</th>\n",
       "      <td>477</td>\n",
       "      <td>731</td>\n",
       "      <td>1</td>\n",
       "      <td>875941275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7882</th>\n",
       "      <td>477</td>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>875941763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7883</th>\n",
       "      <td>477</td>\n",
       "      <td>815</td>\n",
       "      <td>1</td>\n",
       "      <td>875941763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7884</th>\n",
       "      <td>477</td>\n",
       "      <td>451</td>\n",
       "      <td>1</td>\n",
       "      <td>875941763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7885</th>\n",
       "      <td>477</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "      <td>875941763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7886</th>\n",
       "      <td>477</td>\n",
       "      <td>722</td>\n",
       "      <td>1</td>\n",
       "      <td>875941763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7887</th>\n",
       "      <td>477</td>\n",
       "      <td>709</td>\n",
       "      <td>1</td>\n",
       "      <td>875941763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7888</th>\n",
       "      <td>477</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>875941763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7889</th>\n",
       "      <td>477</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>875941763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7890</th>\n",
       "      <td>477</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>875941763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7891</th>\n",
       "      <td>477</td>\n",
       "      <td>1051</td>\n",
       "      <td>1</td>\n",
       "      <td>875941763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7892</th>\n",
       "      <td>477</td>\n",
       "      <td>289</td>\n",
       "      <td>1</td>\n",
       "      <td>875941793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7893</th>\n",
       "      <td>477</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>875941863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7894</th>\n",
       "      <td>477</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>875941888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7895</th>\n",
       "      <td>477</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>875941948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      uid   iid  label       time\n",
       "7863  477   237      1  875940451\n",
       "7864  477   294      1  875940693\n",
       "7865  477    25      1  875940755\n",
       "7866  477   756      1  875940755\n",
       "7867  477   369      1  875940836\n",
       "7868  477   280      1  875941022\n",
       "7869  477    88      1  875941085\n",
       "7870  477   724      1  875941086\n",
       "7871  477   732      1  875941111\n",
       "7872  477   794      1  875941111\n",
       "7873  477    49      1  875941155\n",
       "7874  477   553      1  875941155\n",
       "7875  477   739      1  875941191\n",
       "7876  477   778      1  875941191\n",
       "7877  477   781      1  875941191\n",
       "7878  477    36      1  875941224\n",
       "7879  477  1041      1  875941225\n",
       "7880  477    90      1  875941275\n",
       "7881  477   731      1  875941275\n",
       "7882  477   275      1  875941763\n",
       "7883  477   815      1  875941763\n",
       "7884  477   451      1  875941763\n",
       "7885  477   274      1  875941763\n",
       "7886  477   722      1  875941763\n",
       "7887  477   709      1  875941763\n",
       "7888  477   111      1  875941763\n",
       "7889  477    66      1  875941763\n",
       "7890  477   255      1  875941763\n",
       "7891  477  1051      1  875941763\n",
       "7892  477   289      1  875941793\n",
       "7893  477    15      1  875941863\n",
       "7894  477    20      1  875941888\n",
       "7895  477   282      1  875941948"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.train_df[dataloader.train_df['uid'] == 477]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>477</td>\n",
       "      <td>546</td>\n",
       "      <td>1</td>\n",
       "      <td>875941972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     uid  iid  label       time\n",
       "113  477  546      1  875941972"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.validation_df[dataloader.validation_df['uid'] == 477]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>477</td>\n",
       "      <td>846</td>\n",
       "      <td>1</td>\n",
       "      <td>875942042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     uid  iid  label       time\n",
       "114  477  846      1  875942042"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.test_df[dataloader.test_df['uid'] == 477]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liming/opt/anaconda3/envs/pytorch_test/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df = neg_df\n",
    "neg_data = {}\n",
    "# ['uid', 'iid']\n",
    "out_columns = []\n",
    "\n",
    "if 'uid' in df:\n",
    "    out_columns.append('uid')\n",
    "    neg_data['uid'] = df['uid'].values\n",
    "if 'iid' in df:\n",
    "    out_columns.append('iid')\n",
    "    neg_data['iid'] = df['iid'].values\n",
    "if 'time' in df:\n",
    "    neg_data['time'] = df['time'].values\n",
    "\n",
    "if dataloader.label in df.columns:\n",
    "    neg_data['y'] = np.array(df[dataloader.label], dtype=np.float32)\n",
    "else:\n",
    "    neg_data['y'] = np.zeros(len(df), dtype=np.float32)\n",
    "\n",
    "ui_id = df[out_columns]\n",
    "\n",
    "base = 0\n",
    "for feature in ui_id.columns:\n",
    "    ui_id[feature] = ui_id[feature].apply(lambda x: x + base)\n",
    "    base += int(dataloader.column_max[feature] + 1)\n",
    "\n",
    "neg_data['x'] = ui_id.values.astype(int) # ui_id.values 把 dataframe 转换成了 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uid': array([259, 259, 259, ..., 729, 729, 729]),\n",
       " 'iid': array([255, 286, 298, ..., 300, 333, 689]),\n",
       " 'time': array([874724710, 874724727, 874724754, ..., 893286638, 893286638,\n",
       "        893286638]),\n",
       " 'y': array([1., 1., 1., ..., 1., 1., 1.], dtype=float32),\n",
       " 'x': array([[ 259, 1199],\n",
       "        [ 259, 1230],\n",
       "        [ 259, 1242],\n",
       "        ...,\n",
       "        [ 729, 1244],\n",
       "        [ 729, 1277],\n",
       "        [ 729, 1633]])}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_df = pd.DataFrame()\n",
    "for c in ['uid', 'iid', 'y', 'time']:\n",
    "    if c in data:\n",
    "        inter_df[c] = data[c]\n",
    "    else:\n",
    "        assert c == 'time'\n",
    "\n",
    "# neg_df = self.generate_neg_df(inter_df=inter_df,\n",
    "#                              feature_df=feature_df,\n",
    "#                              sample_n=sample_n, train=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns = [c for c in inter_df.columns if c not in ['uid', 'y']]\n",
    "other_infos = inter_df[other_columns].to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['iid', 'time'])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids, labels, sample_n, train, other_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "train_history_pos = defaultdict(set)\n",
    "for uid in dataloader.train_user_pos.keys():\n",
    "    train_history_pos[uid] = set(dataloader.train_user_pos[uid])\n",
    "\n",
    "validation_history_pos = defaultdict(set)\n",
    "for uid in dataloader.validation_user_pos.keys():\n",
    "    validation_history_pos[uid] = set(dataloader.validation_user_pos[uid])\n",
    "\n",
    "test_history_pos = defaultdict(set)\n",
    "for uid in dataloader.test_user_pos.keys():\n",
    "    test_history_pos[uid] = set(dataloader.test_user_pos[uid])\n",
    "\n",
    "train_history_neg = defaultdict(set)\n",
    "for uid in dataloader.train_user_neg.keys():\n",
    "    train_history_neg[uid] = set(dataloader.train_user_neg[uid])\n",
    "\n",
    "validation_history_neg = defaultdict(set)\n",
    "for uid in dataloader.validation_user_neg.keys():\n",
    "    validation_history_neg[uid] = set(dataloader.validation_user_neg[uid])\n",
    "\n",
    "test_history_neg = defaultdict(set)\n",
    "for uid in dataloader.test_user_neg.keys():\n",
    "    test_history_neg[uid] = set(dataloader.test_user_neg[uid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids = inter_df['uid'].tolist()\n",
    "labels = inter_df['y'].tolist()\n",
    "sample_n = 1\n",
    "train = True\n",
    "\n",
    "\n",
    "iid_list = []\n",
    "other_info_list = {}\n",
    "for info in other_infos:\n",
    "    other_info_list[info] = []\n",
    "\n",
    "item_num = dataloader.item_num\n",
    "for index, uid in enumerate(uids):\n",
    "    if labels[index] > 0:\n",
    "        train_history = train_history_pos\n",
    "        validation_hisotry, test_history = validation_history_pos, test_history_pos\n",
    "\n",
    "    if train:\n",
    "        inter_iids = train_history[uid]\n",
    "    else:\n",
    "        inter_iids = train_history[uid] | validation_hisotry[uid] | test_history[uid]\n",
    "\n",
    "    remain_iids_num = item_num - len(inter_iids)\n",
    "\n",
    "    sampled = set()\n",
    "    unknown_iid_list = []\n",
    "    for i in range(sample_n):\n",
    "        iid = np.random.randint(1, dataloader.item_num)\n",
    "        while iid in inter_iids or iid in sampled:\n",
    "            iid = np.random.randint(1, dataloader.item_num)\n",
    "        unknown_iid_list.append(iid)\n",
    "        sampled.add(iid)\n",
    "\n",
    "    iid_list.append(unknown_iid_list)\n",
    "\n",
    "all_uid_list, all_iid_list = [], []\n",
    "for i in range(sample_n):\n",
    "    for index, uid in enumerate(uids):\n",
    "        all_uid_list.append(uid)\n",
    "        all_iid_list.append(iid_list[index][i])\n",
    "\n",
    "        for info in other_infos:\n",
    "            other_info_list[info].append(other_infos[info][index])\n",
    "\n",
    "neg_df = pd.DataFrame(data=list(zip(all_uid_list, all_iid_list)), columns=['uid', 'iid_neg'])\n",
    "for info in other_infos:\n",
    "    neg_df[info] = other_info_list[info]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>time</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259</td>\n",
       "      <td>1101</td>\n",
       "      <td>874724710</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259</td>\n",
       "      <td>361</td>\n",
       "      <td>874724727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>259</td>\n",
       "      <td>391</td>\n",
       "      <td>874724754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>259</td>\n",
       "      <td>458</td>\n",
       "      <td>874724781</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>259</td>\n",
       "      <td>1049</td>\n",
       "      <td>874724843</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53509</th>\n",
       "      <td>729</td>\n",
       "      <td>471</td>\n",
       "      <td>893286637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53510</th>\n",
       "      <td>729</td>\n",
       "      <td>646</td>\n",
       "      <td>893286637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53511</th>\n",
       "      <td>729</td>\n",
       "      <td>712</td>\n",
       "      <td>893286638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53512</th>\n",
       "      <td>729</td>\n",
       "      <td>23</td>\n",
       "      <td>893286638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53513</th>\n",
       "      <td>729</td>\n",
       "      <td>164</td>\n",
       "      <td>893286638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53514 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid   iid       time  label\n",
       "0      259  1101  874724710      0\n",
       "1      259   361  874724727      0\n",
       "2      259   391  874724754      0\n",
       "3      259   458  874724781      0\n",
       "4      259  1049  874724843      0\n",
       "...    ...   ...        ...    ...\n",
       "53509  729   471  893286637      0\n",
       "53510  729   646  893286637      0\n",
       "53511  729   712  893286638      0\n",
       "53512  729    23  893286638      0\n",
       "53513  729   164  893286638      0\n",
       "\n",
       "[53514 rows x 4 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_df = neg_df.drop(columns=['iid'])\n",
    "neg_df['label'] = 0\n",
    "neg_df = neg_df.rename(columns={'iid_neg': 'iid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uid': array([259, 259, 259, ..., 729, 729, 729]),\n",
       " 'iid': array([1101,  361,  391, ...,  712,   23,  164]),\n",
       " 'time': array([874724710, 874724727, 874724754, ..., 893286638, 893286638,\n",
       "        893286638]),\n",
       " 'y': array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " 'x': array([[ 259, 1199],\n",
       "        [ 259, 1230],\n",
       "        [ 259, 1242],\n",
       "        ...,\n",
       "        [ 729, 1244],\n",
       "        [ 729, 1277],\n",
       "        [ 729, 1633]]),\n",
       " 'sample_id': array([    0,     1,     2, ..., 53511, 53512, 53513])}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['y'] = np.ones(len(data['uid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sample_id'] = np.arange(0, len(data['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data['sample_id'] = np.arange(0, len(neg_data['y'])) + len(data['sample_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def numpy_to_torch(d, gpu=False, requires_grad=True):\n",
    "    t = torch.from_numpy(d)\n",
    "    if d.dtype is np.float:\n",
    "        t.requires_grad = requires_grad\n",
    "    if gpu and torch.cuda.device_count() > 0:\n",
    "        t = t.cuda()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_start = 0\n",
    "batch_size = 128\n",
    "total_data_num = len(data['sample_id'])\n",
    "batch_end = min(len(data['uid']), batch_start + batch_size)\n",
    "real_batch_size = batch_end - batch_start\n",
    "total_batch_size = real_batch_size * (1 + 1)\n",
    "\n",
    "feed_dict = {'train': train, 'real_batch_size': real_batch_size, 'total_batch_size': total_batch_size}\n",
    "\n",
    "feed_dict['y'] = numpy_to_torch(data['y'][batch_start:batch_start + real_batch_size])\n",
    "for c in ['uid', 'iid', 'x', 'sample_id', 'time', 'history']:\n",
    "    d = data[c][batch_start: batch_start + real_batch_size]\n",
    "    \n",
    "    if train:\n",
    "        neg_d = np.concatenate([neg_data[c][total_data_num * i + batch_start: total_data_num * i + batch_start + real_batch_size]\n",
    "                               for i in range(1)])\n",
    "\n",
    "        d = np.concatenate([d, neg_d])\n",
    "    feed_dict[c] = d\n",
    "\n",
    "for c in ['uid', 'iid', 'x']:\n",
    "    feed_dict[c] = numpy_to_torch(feed_dict[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feed_dict['uid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'real_batch_size', 'total_batch_size', 'y', 'uid', 'iid', 'x', 'sample_id', 'time'])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataloader.train_df[dataloader.train_df['history'].apply(lambda x: len(x) > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([255]), list([255, 286]), list([255, 286, 298]), ...,\n",
       "       list([-879, -751, -294, -338, -901, -683, -894, 354, 322, 362]),\n",
       "       list([-751, -294, -338, -901, -683, -894, 354, 322, 362, 300]),\n",
       "       list([-294, -338, -901, -683, -894, 354, 322, 362, 300, 333])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "his = df['history'].apply(lambda x: eval('[' + x + ']'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor(vector1.size()[:-1]).uniform_(0, 1).bernoulli()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-219-6dbeb3936fab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "tensor1 = tensor([[ 1.4718e-02, -3.7019e-03, -6.8673e-03, -5.5302e-03,\n",
    "          4.1877e-03, -4.9621e-03],\n",
    "        [-3.2222e-03, -1.2830e-02, -8.6446e-03, 7.7203e-03,\n",
    "         -1.5384e-02, -5.6847e-03],\n",
    "        [ 4.0225e-03,  1.1947e-02, -2.4000e-02, 6.9259e-03,\n",
    "          2.3533e-02, -1.5013e-02]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tensor1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = tensor([[1, 2, 2, 2], [4, 5, 5, 5]])\n",
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tensor([[1, 2, 3, 7], [4, 5, 6, 8]])\n",
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (4) must match the existing size (3) at non-singleton dimension 1.  Target sizes: [2, 4].  Tensor sizes: [2, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-236-6f1c5cdb93b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (4) must match the existing size (3) at non-singleton dimension 1.  Target sizes: [2, 4].  Tensor sizes: [2, 3]"
     ]
    }
   ],
   "source": [
    "t1.expand_as(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "r12 = torch.Tensor(2).uniform_(0, 1).bernoulli().unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 7.],\n",
       "        [4., 5., 5., 5.]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r12 * t2 + (1 - r12) * t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [4., 5., 5., 5.]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 - r12) * t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 2, 2, 1, 2, 3, 7],\n",
       "        [4, 5, 5, 5, 4, 5, 6, 8]])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((t1, t2), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.Tensor([[1, 2, 3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg = torch.Tensor([[1, -1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2500, 0.2500, 0.2500, 0.2500]])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.Tensor([[0, 0, 0, 0]])).softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1., -2.,  3.])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((t1 * pos_neg) * (t1 * pos_neg).softmax(dim=0)).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., -2.,  3.]])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t1 * pos_neg) * (t1 * pos_neg).softmax(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4.],\n",
       "        [1., 2., 3., 4.]])"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.expand_as(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[2., 3.],\n",
       "         [1., 2.]]])"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[4., 5.],\n",
       "         [6., 7.]]])"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.Tensor([[[1, 2], [3, 4]], [[2, 3], [1, 2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "result = F.cosine_similarity(t1, torch.from_numpy(np.zeros(t1.size())), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.zeros(t1.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[2., 3.],\n",
       "         [1., 2.]]])"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., dtype=torch.float64)"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 5.],\n",
       "         [6., 7.]],\n",
       "\n",
       "        [[1., 2.],\n",
       "         [3., 4.]]])"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2[torch.randperm(t2.size()[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[4., 5.],\n",
       "         [6., 7.]]])"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2361, 5.0000],\n",
       "        [6.4031, 9.2195]])"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.norm(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(22.8587)"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.norm(dim=2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = t1.view([-1, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = t1.expand_as(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (t1 / t1.sum(dim=-1).view([2, 1])).view([2, -1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3333],\n",
       "         [0.6667]],\n",
       "\n",
       "        [[0.1667],\n",
       "         [0.8333]]])"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 1])"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[4., 5.],\n",
       "         [6., 7.]]])"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3333, 0.6667],\n",
       "         [2.0000, 2.6667]],\n",
       "\n",
       "        [[0.6667, 0.8333],\n",
       "         [5.0000, 5.8333]]])"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t2 * t).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3333, 3.3333],\n",
       "        [5.6667, 6.6667]])"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t2 * t).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2])"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.]],\n",
       "\n",
       "        [[1., 5.]]])"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[4., 5.],\n",
       "         [6., 7.]]])"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9839],\n",
       "        [0.8882, 0.8721]])"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cosine_similarity(t1, t2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0000, 1.9839],\n",
       "        [1.8882, 1.8721]])"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cosine_similarity(t1, t2, dim=-1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[4., 5.],\n",
       "         [6., 7.]]])"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = torch.nn.Linear(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = inter(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3612, 0.2748],\n",
       "         [0.8749, 0.9574]],\n",
       "\n",
       "        [[1.4696, 1.6543],\n",
       "         [1.9834, 2.3369]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.view([2, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.view([2, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = torch.norm(res, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.4683, 7.4442], grad_fn=<NormBackward1>)"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1463, 0.1113, 0.3545, 0.3879],\n",
       "        [0.1974, 0.2222, 0.2664, 0.3139]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res / l2.view([-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[2., 3.],\n",
       "         [1., 2.]]])"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 1])"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.Tensor([[[0.1], [0.2]], [[0.3], [0.4]]])\n",
    "t2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1000],\n",
       "         [0.2000]],\n",
       "\n",
       "        [[0.3000],\n",
       "         [0.4000]]])"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7000, 1.0000],\n",
       "        [1.0000, 1.7000]])"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t1 * t2).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t1 * t2).sum(dim=1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1000, 0.2000],\n",
       "         [0.6000, 0.8000]],\n",
       "\n",
       "        [[0.6000, 0.9000],\n",
       "         [0.4000, 0.8000]]])"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 * t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = torch.cat((t2, t1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 1., 2.],\n",
       "         [3., 4., 1., 2.]],\n",
       "\n",
       "        [[4., 5., 1., 5.],\n",
       "         [6., 7., 1., 5.]]])"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = torch.Tensor([[[1, 2], [3, 4]],\n",
    "                  [[4, 5], [6, 7]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
